\chapter{Conclusions and Future Works}

\section{Conclusions}

The aim of this project was to serve as a Proof of Concept on how MRI brain images could be artificially generated with Variational Autoencoders which ultimately would serve to enhance existing or new datasets to improve model accuracy by having bigger samples of data.

According to the original aim of the project, it can be concluded that, as a Proof of Concept, Variational Autoencoders can create images artificially. This project requires to be continued so that those created images could be interpreted as real by an expert eye.

Training the different models and convolutional networks with also different parameters, produced similar images. That leads to conclude that maybe the \GLSname{ixi} dataset was too small or that the selected approach to decide which images to pre-process and use was not the best. While thesis' dataset generated (and used) ~16k images, BraTS \cite{brats} uses ~165k, ten times more images for anomaly detection models. So, it is clear that the number of images used in this project is far from being appropiate.

The models were able to create images that overall can be seen as brain images in terms of sizes and forms, but the brains are not detailed, instead, they look blurred. This is the main area of improvement and were a second phase of the project should focus.

Since this project implemented both Variational Autoencoders and Vector-Quantized VAEs it is ready to show the benefits of using one or the other. While they had the same imaging results due to previous conclusions, the latter has shown better learning times by reducing about 5-10 seconds on each epoch train.

The project timeline was a little short to execute some additional experiments that could have given better outcomes out of this proof of concept and it looks really short to achieve the final goal of the models. It must be taken into consideration that the researching aspects of the project were a lot, including \acrshort{mri} learning and cutting edge VAE models which require to learn and implement losses calculations and latent space fundamental concepts. Also, training any of the 2 models requires few hours and it would require more in case of increasing the size of the dataset.

It looks the right decision to have taken the opportunity to train VAEs for image creation rather than using Autoencoders to reconstruct existing images since VAEs were not only capable of that but also of creating new images from the latent space. Using Autoencoders would have required less efforts in research while focusing on tuning model results from previous existing and documented projects.

Using Google Colab and Keras library proved to be the right tools to use, both of them boosted the project thanks to the community behind who have created reference projects to implement new VAE and VQ-VAE classes for models. The downside of using Colab is that free GPUs are very limited to this kind of project even when using the PRO+ subscription, paid unites lasted for 2 days. Maybe for this kind of projects, dedicated VMs should be used to not block the project activities.

\section{Future Work}

As described in conclusions, this thesis outcomes prove that VAEs and VQ-VAEs are learning from the dataset but that they cannot create real images today. To reach that goal, several future works are foreseen.

If the project sticks to use \GLSname{ixi} dataset and work with 2D slices, the images should be intensively processed by applying skull stripping and, at least, adding noise and centering images as pre-processing techniques that might improve the dataset quality.

Clearly, the KL-Divergence issue has to be cleared out. Maximizing ELBOs require to minimize both reconstruction loss and KL-divergence, it is not an option to let KL-divergence to increase. Another related task is to work on the formula that aggregates reconstruction loss and KL-divergence as training loss. Maybe applying factors is needed. 

Talking about losses, a nice-to-have task is to be able to mark which are the values that are acceptable. For example, in case of reconstruction loss, a loss of 0 means that images are identical, but what does mean a loss of 30? or a loss of 100? If acceptable losses can be determined the expert eye would not be required to declare a model as good or bad.

In case that the \GLSname{ixi} dataset could be extended with other MRI datasets, for instance BraTS \cite{brats}, the models should be trained with them first, and then with both. Exploring results with larger datasets is key to test the implemented VAE and VQ-VAE models' quality.