{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtablado/uoc2022_tfm/blob/main/vq-vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://learnopencv.com/variational-autoencoder-in-tensorflow/\n",
        "\n",
        "https://keras.io/examples/generative/vae/"
      ],
      "metadata": {
        "id": "yHasBMHRxHb8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_dhLG4xZbM9y"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers                                                                                                                                                                                                                                                                                                                                       \n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Adadelta, Adagrad\n",
        "import numpy as np\n",
        "import math                                                                                                                 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "metadata": {
        "id": "edtgkvZzbWoW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# Force the mount due to several errors with drive sync\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJFQ5I2cbZtm",
        "outputId": "d3eb614d-b985-43b5-a653-9b04b2c96e64"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "9el8GlkAbaS0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_encoder():\n",
        "  latent_dim = 2\n",
        "\n",
        "  inputs = keras.Input(shape=(256, 256, 1), name='input_layer')\n",
        "\n",
        "  # Block-1\n",
        "  x = layers.Conv2D(32, kernel_size=3, strides= 2, padding='same', name='conv_1')(inputs)\n",
        "  x = layers.BatchNormalization(name='bn_1')(x)\n",
        "  x = layers.LeakyReLU(name='lrelu_1')(x)\n",
        "\n",
        "  # Block-2\n",
        "  x = layers.Conv2D(64, kernel_size=3, strides= 2, padding='same', name='conv_2')(x)\n",
        "  x = layers.BatchNormalization(name='bn_2')(x)\n",
        "  x = layers.LeakyReLU(name='lrelu_2')(x)\n",
        "\n",
        "  # Block-3\n",
        "  x = layers.Conv2D(64, 3, 2, padding='same', name='conv_3')(x)\n",
        "  x = layers.BatchNormalization(name='bn_3')(x)\n",
        "  x = layers.LeakyReLU(name='lrelu_3')(x)\n",
        "\n",
        "  # Block-4\n",
        "  x = layers.Conv2D(64, 3, 2, padding='same', name='conv_4')(x)\n",
        "  x = layers.BatchNormalization(name='bn_4')(x)\n",
        "  x = layers.LeakyReLU(name='lrelu_4')(x)\n",
        "\n",
        "  # Block-5\n",
        "  x = layers.Conv2D(64, 3, 2, padding='same', name='conv_5')(x)\n",
        "  x = layers.BatchNormalization(name='bn_5')(x)\n",
        "  x = layers.LeakyReLU(name='lrelu_5')(x)\n",
        "\n",
        "  # Final Block\n",
        "  flatten = layers.Flatten()(x)\n",
        "  mean = layers.Dense(200, name='mean')(flatten)\n",
        "  log_var = layers.Dense(200, name='log_var')(flatten)\n",
        "  z = Sampling()([mean, log_var])\n",
        "  model = tf.keras.Model(inputs, (mean, log_var, z), name=\"Encoder\")\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "encoder = vae_encoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUVpfaJIbkj2",
        "outputId": "d8d1e846-839a-4077-df19-7f3a0e307f6b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_layer (InputLayer)       [(None, 256, 256, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv_1 (Conv2D)                (None, 128, 128, 32  320         ['input_layer[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bn_1 (BatchNormalization)      (None, 128, 128, 32  128         ['conv_1[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_1 (LeakyReLU)            (None, 128, 128, 32  0           ['bn_1[0][0]']                   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv_2 (Conv2D)                (None, 64, 64, 64)   18496       ['lrelu_1[0][0]']                \n",
            "                                                                                                  \n",
            " bn_2 (BatchNormalization)      (None, 64, 64, 64)   256         ['conv_2[0][0]']                 \n",
            "                                                                                                  \n",
            " lrelu_2 (LeakyReLU)            (None, 64, 64, 64)   0           ['bn_2[0][0]']                   \n",
            "                                                                                                  \n",
            " conv_3 (Conv2D)                (None, 32, 32, 64)   36928       ['lrelu_2[0][0]']                \n",
            "                                                                                                  \n",
            " bn_3 (BatchNormalization)      (None, 32, 32, 64)   256         ['conv_3[0][0]']                 \n",
            "                                                                                                  \n",
            " lrelu_3 (LeakyReLU)            (None, 32, 32, 64)   0           ['bn_3[0][0]']                   \n",
            "                                                                                                  \n",
            " conv_4 (Conv2D)                (None, 16, 16, 64)   36928       ['lrelu_3[0][0]']                \n",
            "                                                                                                  \n",
            " bn_4 (BatchNormalization)      (None, 16, 16, 64)   256         ['conv_4[0][0]']                 \n",
            "                                                                                                  \n",
            " lrelu_4 (LeakyReLU)            (None, 16, 16, 64)   0           ['bn_4[0][0]']                   \n",
            "                                                                                                  \n",
            " conv_5 (Conv2D)                (None, 8, 8, 64)     36928       ['lrelu_4[0][0]']                \n",
            "                                                                                                  \n",
            " bn_5 (BatchNormalization)      (None, 8, 8, 64)     256         ['conv_5[0][0]']                 \n",
            "                                                                                                  \n",
            " lrelu_5 (LeakyReLU)            (None, 8, 8, 64)     0           ['bn_5[0][0]']                   \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 4096)         0           ['lrelu_5[0][0]']                \n",
            "                                                                                                  \n",
            " mean (Dense)                   (None, 200)          819400      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " log_var (Dense)                (None, 200)          819400      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " sampling (Sampling)            (None, 200)          0           ['mean[0][0]',                   \n",
            "                                                                  'log_var[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,769,552\n",
            "Trainable params: 1,768,976\n",
            "Non-trainable params: 576\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_decoder():\n",
        "  inputs = keras.Input(shape=(200,), name='input_layer')\n",
        "  x = layers.Dense(4096, name='dense_1')(inputs)\n",
        "  x = layers.Reshape((8,8,64), name='Reshape')(x)\n",
        "\n",
        "  # Block-1\n",
        "  x = layers.Conv2DTranspose(64, 3, strides= 2, padding='same',name='conv_transpose_1')(x)\n",
        "  x = layers.BatchNormalization(name='bn_1')(x)\n",
        "  x = layers.LeakyReLU(name='lrelu_1')(x)\n",
        "\n",
        "  # Block-2\n",
        "  x = layers.Conv2DTranspose(64, 3, strides= 2, padding='same', name='conv_transpose_2')(x)\n",
        "  x = layers.BatchNormalization(name='bn_2')(x)\n",
        "  x = layers.LeakyReLU(name='lrelu_2')(x)\n",
        "\n",
        "  # Block-3\n",
        "  x = layers.Conv2DTranspose(64, 3, 2, padding='same', name='conv_transpose_3')(x)\n",
        "  x = layers.BatchNormalization(name='bn_3')(x)\n",
        "  x = layers.LeakyReLU(name='lrelu_3')(x)\n",
        "\n",
        "  # Block-4\n",
        "  x = layers.Conv2DTranspose(32, 3, 2, padding='same', name='conv_transpose_4')(x)\n",
        "  x = layers.BatchNormalization(name='bn_4')(x)\n",
        "  x = layers.LeakyReLU(name='lrelu_4')(x)\n",
        "\n",
        "  # Block-5\n",
        "  outputs = layers.Conv2DTranspose(1, 3, 2,padding='same', activation='sigmoid', name='conv_transpose_5')(x)\n",
        "  model = tf.keras.Model(inputs, outputs, name=\"Decoder\")\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "decoder = vae_decoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAvh0mpMbn0i",
        "outputId": "1283dce4-5847-41fa-aac3-aea0e4dc339e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 200)]             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              823296    \n",
            "                                                                 \n",
            " Reshape (Reshape)           (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv_transpose_1 (Conv2DTra  (None, 16, 16, 64)       36928     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " bn_1 (BatchNormalization)   (None, 16, 16, 64)        256       \n",
            "                                                                 \n",
            " lrelu_1 (LeakyReLU)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv_transpose_2 (Conv2DTra  (None, 32, 32, 64)       36928     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " bn_2 (BatchNormalization)   (None, 32, 32, 64)        256       \n",
            "                                                                 \n",
            " lrelu_2 (LeakyReLU)         (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv_transpose_3 (Conv2DTra  (None, 64, 64, 64)       36928     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " bn_3 (BatchNormalization)   (None, 64, 64, 64)        256       \n",
            "                                                                 \n",
            " lrelu_3 (LeakyReLU)         (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " conv_transpose_4 (Conv2DTra  (None, 128, 128, 32)     18464     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " bn_4 (BatchNormalization)   (None, 128, 128, 32)      128       \n",
            "                                                                 \n",
            " lrelu_4 (LeakyReLU)         (None, 128, 128, 32)      0         \n",
            "                                                                 \n",
            " conv_transpose_5 (Conv2DTra  (None, 256, 256, 1)      289       \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 953,729\n",
            "Trainable params: 953,281\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            \n",
        "            # The reconstruction loss measures how close the decoder output is to the original input by using the mean-squared error (MSE)\n",
        "            r_loss = tf.reduce_mean(tf.square(data - reconstruction), axis = [1,2,3])\n",
        "            reconstruction_loss = 1000 * r_loss\n",
        "            \n",
        "            #reconstruction_loss = tf.reduce_mean(\n",
        "            #    tf.reduce_sum(\n",
        "            #        keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
        "            #    )\n",
        "            #)\n",
        "\n",
        "            #reconstruction_loss = keras.metrics.mean_squared_error(data, reconstruction)\n",
        "\n",
        "            # The KL loss, or Kullback–Leibler divergence, measures the difference between two probability distributions. \n",
        "            # Minimizing the KL loss in this case means ensuring that the learned means and variances are as close as possible to those of the target (normal) distribution. \n",
        "            # For a latent dimension of size K\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "\n",
        "            #kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "\n",
        "            #kl = tf.keras.losses.KLDivergence()\n",
        "            #kl_loss = tf.reduce_mean(tf.reduce_sum(kl(data, reconstruction)))\n",
        "\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        result = {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "        return result \n"
      ],
      "metadata": {
        "id": "zmxHbPG4brFe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images stored with *matplotlib.imsave* are not normalized, so we will rescale the pixels while reading\n",
        "\n",
        "https://medium.com/analytics-vidhya/understanding-image-augmentation-using-keras-tensorflow-a6341669d9ca"
      ],
      "metadata": {
        "id": "Y-cgnWmaS42y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "path_to_file=\"/content/drive/My Drive/tfm/dataset/slices/training/t1/IXI002-Guys-0828-T1_0.png\"\n",
        "img=cv2.imread(path_to_file,0)# read in image as grayscale\n",
        "max_pixel_value=np.max(img) #  find maximum pixel value\n",
        "min_pixel_value=np.min(img) # find minimum pixel value\n",
        "print('max pixel value= ', max_pixel_value, '  min pixel value= ', min_pixel_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chdofdGQSMBN",
        "outputId": "d55e5190-b519-4ccd-ba1f-576eea8665c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max pixel value=  255   min pixel value=  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/tfm/dataset/slices-160-190\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255 # To normalize values\n",
        "    )\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'training',\n",
        "        target_size=(256, 256),\n",
        "        batch_size=64, # Number of images processed together\n",
        "        color_mode='grayscale',\n",
        "        class_mode=None)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        'test',\n",
        "        target_size=(256, 256),\n",
        "        batch_size=64,\n",
        "        color_mode='grayscale',\n",
        "        class_mode=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naTJxG4kbtfA",
        "outputId": "e125bdfd-8853-433e-8ebb-783a01ea3b4d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1yKlrvb9Cp3amASiDUettfP3V1KJuzGDe/tfm/dataset/slices-160-190\n",
            "Found 16268 images belonging to 1 classes.\n",
            "Found 1162 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0005))\n",
        "\n",
        "# Entrenar el modelo\n",
        "t0 = timeit.default_timer()\n",
        "\n",
        "mfit = vae.fit(train_generator, epochs=30, batch_size=64)\n",
        "training_time_ann = timeit.default_timer() - t0"
      ],
      "metadata": {
        "id": "FcpHzj4lbv-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f5c64f0-3ecb-49e9-c5dd-3e65543cfbb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "  3/255 [..............................] - ETA: 3:53:51 - loss: 149.5870 - reconstruction_loss: 146.5666 - kl_loss: 1.6019"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Plot del training loss y el accuracy\n",
        "def plot_loss(n_epochs, mfit):\n",
        "  loss = mfit.history['loss']\n",
        "  rec_loss = mfit.history['reconstruction_loss']\n",
        "  kl_loss = mfit.history['kl_loss']\n",
        "  \n",
        "  epochs = range(0,n_epochs)\n",
        "  plt.subplots(figsize=(15,10))\n",
        "  plt.plot(epochs, loss, 'g', label='Training Loss')\n",
        "  plt.plot(epochs, rec_loss, 'y', label='Reconstruction Loss')\n",
        "  plt.plot(epochs, kl_loss, 'b', label='Kullback-Leibler Loss')\n",
        "\n",
        "  plt.title('Model Loss and Accuracy')\n",
        "  plt.xticks(epochs)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Total')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "plot_loss(30, mfit)"
      ],
      "metadata": {
        "id": "s6zbV0-Fe9yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean, log_var, z = encoder.predict(test_generator)\n",
        "y_pred = decoder.predict(z)"
      ],
      "metadata": {
        "id": "pQmE3c9IffDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "number_of_images = 10 #len(y_pred)\n",
        "fig, axes = plt.subplots(1, number_of_images, figsize=(25,25))\n",
        "\n",
        "# Show some images\n",
        "for i in range(len([0,1,2,3,4,5,6,7,8,9])):\n",
        "  image = y_pred[i]\n",
        "  image = image[:,:,0]\n",
        "  axes[i].imshow(image, cmap=\"gray\", origin=\"lower\")\n",
        "  # Display the first image in training data\n",
        "  #img = image[:,:,100]\n",
        "  plt.imshow(image, cmap='gray')"
      ],
      "metadata": {
        "id": "2WzhFpp3fn80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[15,15])\n",
        "\n",
        "# Display the first image in training data\n",
        "plt.subplot(121)\n",
        "plt.imshow(image, cmap='gray')"
      ],
      "metadata": {
        "id": "XAiOd1vNhkbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create images from the latent space"
      ],
      "metadata": {
        "id": "FR2W2jei1qZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figsize = 15\n",
        "\n",
        "x = np.random.normal(size = (10,200))\n",
        "reconstruct = decoder.predict(x)\n",
        "\n",
        "fig = plt.figure(figsize=(figsize, 10))\n",
        "\n",
        "for i in range(10):\n",
        "  ax = fig.add_subplot(5, 5, i+1)\n",
        "  ax.axis('off')\n",
        "  pred = reconstruct[i, :, :, :] * 255\n",
        "  pred = np.array(pred)  \n",
        "  pred = pred.astype(np.uint8)\n",
        "  ax.imshow(pred[:,:,0], cmap='gray')"
      ],
      "metadata": {
        "id": "qj50iWLb1hks"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}